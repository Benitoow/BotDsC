# ğŸ“ Changelog

Tous les changements notables de ce projet seront documentÃ©s dans ce fichier.

## [1.2.0] - 2025-10-15 ğŸš€

### âœ¨ AjoutÃ©

#### ğŸ§  SystÃ¨me de Contexte Massif
- **Contexte 32K tokens** : Le bot peut maintenant traiter jusqu'Ã  32,768 tokens de contexte (Ã©quivalent Ã  ~24,000 mots)
- **150 messages en mÃ©moire** : Augmentation drastique de 12 Ã  150 messages gardÃ©s en mÃ©moire active
- **Stockage sur fichiers** : Historique complet illimitÃ© stockÃ© dans `data/conversations/`
- **Compression intelligente** : Les anciennes conversations sont automatiquement compressÃ©es en rÃ©sumÃ©s
- **Base de connaissances** : Extraction automatique de faits (nom, Ã¢ge, prÃ©fÃ©rences, etc.)
- **Recherche sÃ©mantique** : Recherche rapide dans tout l'historique d'un utilisateur
- **MÃ©moire Ã  3 niveaux** : Court terme (RAM), moyen terme (rÃ©sumÃ©s), long terme (disque)

#### ğŸ› ï¸ Outils de gestion
- **Script `manage-context.ps1`** : Outil CLI pour gÃ©rer le contexte
  - `stats` : Statistiques globales
  - `user <id>` : Stats par utilisateur
  - `top` : Top 10 des utilisateurs actifs
  - `cleanup` : Nettoyage des donnÃ©es anciennes
  - `backup` : Sauvegarde complÃ¨te
  - `export <id>` : Export d'historique

#### ğŸ“š Documentation
- **MASSIVE-CONTEXT.md** : Documentation complÃ¨te du systÃ¨me de contexte
- Architecture dÃ©taillÃ©e
- Guide d'utilisation
- RÃ©fÃ©rences et troubleshooting

### ğŸ”§ ModifiÃ©

- **ollama.js** : ParamÃ¨tres optimisÃ©s pour contextes massifs
  - `num_ctx: 32768` : Support de 32K tokens
  - `num_predict: 256-512` : RÃ©ponses plus longues et dÃ©taillÃ©es
  - `num_thread: 8` : Utilisation de 8 threads
  - `num_gpu: 99` : Tous les GPUs disponibles
  
- **index.js** : IntÃ©gration du contexte massif
  - Augmentation de `AI_MEMORY_LENGTH` Ã  150
  - Appels au systÃ¨me `massive-context`
  - Extraction automatique de connaissances

- **.env.example** : Nouvelles variables
  - `OLLAMA_CONTEXT_SIZE=32768`
  - `AI_MEMORY_LENGTH=150`

- **package.json** : Version 1.2.0
  - Nouveaux scripts npm pour gestion du contexte

### ğŸ¯ Performances

| MÃ©trique | Avant (v1.0) | Maintenant (v1.2) | AmÃ©lioration |
|----------|--------------|-------------------|--------------|
| Messages en RAM | 12 | 150 | **+1150%** |
| Contexte tokens | 4K | 32K | **+700%** |
| Historique | ~24 messages | IllimitÃ© | **âˆ** |
| MÃ©moire par user | ~5 KB | ~100 KB | OptimisÃ© sur disque |

### ğŸ“Š Comparaison avec ChatGPT

| FonctionnalitÃ© | BotDsC v1.2 | ChatGPT-4 | ChatGPT-3.5 |
|----------------|-------------|-----------|-------------|
| Contexte tokens | 32K | 128K | 16K |
| MÃ©moire persistante | âœ… IllimitÃ©e | âœ… LimitÃ©e | âŒ |
| Recherche historique | âœ… | âŒ | âŒ |
| Base de connaissances | âœ… | âŒ | âŒ |
| Compression auto | âœ… | âœ… | âœ… |

---

## [1.0.0] - 2025-10-14

### âœ¨ AjoutÃ© (Release initiale)

- ğŸ¤– Bot Discord avec IA locale (Ollama)
- ğŸ§  Moteur de raisonnement avancÃ©
- ğŸ’¾ MÃ©moire intelligente smart-memory.js
- ğŸ­ Comportement proactif
- ğŸ“Š SystÃ¨me de profils utilisateurs
- ğŸ¯ DÃ©tection d'intentions
- ğŸŒ¡ï¸ Analyse Ã©motionnelle
- âš¡ Configuration GPU/CPU automatique
- ğŸ‡«ğŸ‡· OptimisÃ© pour le franÃ§ais
- ğŸ“ Scripts PowerShell de gestion

### ğŸ”§ Configuration

- Support Mixtral 8x7B et Mistral 7B
- MÃ©moire contextuelle de 12 messages
- PersonnalitÃ© libÃ©rale et dÃ©complexÃ©e
- Multi-serveurs et DM

---

## Format

Ce changelog suit le format [Keep a Changelog](https://keepachangelog.com/fr/1.0.0/),
et ce projet adhÃ¨re au [Semantic Versioning](https://semver.org/lang/fr/).

### Types de changements

- **AjoutÃ©** : pour les nouvelles fonctionnalitÃ©s
- **ModifiÃ©** : pour les changements aux fonctionnalitÃ©s existantes
- **DÃ©prÃ©ciÃ©** : pour les fonctionnalitÃ©s bientÃ´t supprimÃ©es
- **SupprimÃ©** : pour les fonctionnalitÃ©s supprimÃ©es
- **CorrigÃ©** : pour les corrections de bugs
- **SÃ©curitÃ©** : en cas de vulnÃ©rabilitÃ©s
