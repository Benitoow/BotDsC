# ğŸš€ SystÃ¨me de Contexte Massif

## Vue d'ensemble

Le bot intÃ¨gre dÃ©sormais un **systÃ¨me de contexte massif** qui rivalise avec ChatGPT en termes de mÃ©moire et de comprÃ©hension contextuelle.

## ğŸ“Š CapacitÃ©s

### Avant (v1.0)
- âœ… 12 messages en mÃ©moire
- âœ… ~4K tokens de contexte
- âœ… RÃ©sumÃ©s basiques

### Maintenant (v1.2) ğŸš€
- âœ… **150 messages en mÃ©moire active** (12x plus !)
- âœ… **32K tokens de contexte** (8x plus !)
- âœ… **Historique illimitÃ© sur fichiers**
- âœ… **Compression intelligente** des conversations
- âœ… **Recherche sÃ©mantique** dans l'historique
- âœ… **Extraction automatique** de connaissances
- âœ… **Base de connaissances persistante**

## ğŸ§  Architecture

### 1. MÃ©moire Ã  3 niveaux

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰MOIRE COURTE (150 messages)      â”‚ â† Contexte immÃ©diat
â”‚  - Conversations rÃ©centes           â”‚
â”‚  - DÃ©tails complets                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰MOIRE MOYENNE (RÃ©sumÃ©s)          â”‚ â† Compressions intelligentes
â”‚  - RÃ©sumÃ©s de pÃ©riodes passÃ©es      â”‚
â”‚  - Sujets principaux                â”‚
â”‚  - Ton Ã©motionnel                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰MOIRE LONGUE (Fichiers)          â”‚ â† Stockage permanent
â”‚  - Historique complet               â”‚
â”‚  - Base de connaissances            â”‚
â”‚  - Faits extraits                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Structure des fichiers

```
data/
â”œâ”€â”€ conversations/          # Historiques complets par utilisateur
â”‚   â”œâ”€â”€ 123456789.json     # Un fichier par utilisateur
â”‚   â”œâ”€â”€ 987654321.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ knowledge-base.json    # Base de connaissances globale
â”œâ”€â”€ smart-memory.json      # MÃ©moire intelligente
â”œâ”€â”€ user-profiles.json     # Profils utilisateurs
â””â”€â”€ reasoning-cache.json   # Cache de raisonnement
```

### 3. Format de conversation (exemple)

```json
{
  "userId": "123456789",
  "messages": [
    {
      "role": "user",
      "content": "Salut !",
      "timestamp": 1697123456789,
      "metadata": { "userName": "John" }
    },
    {
      "role": "assistant",
      "content": "Hey !",
      "timestamp": 1697123457890
    }
  ],
  "summaries": [
    {
      "timestamp": 1697000000000,
      "messageCount": 100,
      "topics": ["gaming", "musique", "politique"],
      "emotionalTone": "positive",
      "keyPhrases": ["j'adore ce jeu", "la musique c'est la vie"]
    }
  ],
  "totalMessages": 523,
  "firstMessage": 1696000000000,
  "lastMessage": 1697123457890
}
```

## âš™ï¸ Configuration

### Variables d'environnement

```env
# Taille du contexte Ollama (en tokens)
OLLAMA_CONTEXT_SIZE=32768    # 32K tokens (Mixtral max)

# Nombre de messages en mÃ©moire active
AI_MEMORY_LENGTH=150         # 150 messages rÃ©cents
```

### Limites par modÃ¨le

| ModÃ¨le | Contexte Max | RecommandÃ© | Performance |
|--------|-------------|------------|-------------|
| **Mixtral 8x7B** | 32K tokens | 32K | Excellent |
| **Mistral 7B** | 8K tokens | 8K | TrÃ¨s bon |
| **Mixtral Instruct** | 32K tokens | 32K | Excellent |

## ğŸ” FonctionnalitÃ©s avancÃ©es

### 1. Compression automatique

Quand le nombre de messages dÃ©passe 200, les 100 plus anciens sont automatiquement compressÃ©s en un rÃ©sumÃ© intelligent :

```javascript
// Exemple de rÃ©sumÃ© gÃ©nÃ©rÃ©
{
  "messageCount": 100,
  "topics": ["gaming", "musique", "politique", "vie", "Ã©tudes"],
  "emotionalTone": "positive",
  "keyPhrases": [
    "j'adore ce jeu",
    "la musique c'est la vie",
    "les Ã©tudes c'est chiant"
  ],
  "timeRange": { "start": ..., "end": ... }
}
```

### 2. Extraction de connaissances

Le bot extrait automatiquement :
- âœ… **Nom** : "je m'appelle John"
- âœ… **Ã‚ge** : "j'ai 25 ans"
- âœ… **PrÃ©fÃ©rences** : "j'aime le gaming"
- âœ… **DÃ©goÃ»ts** : "je dÃ©teste les Ã©pinards"

### 3. Recherche sÃ©mantique

```javascript
// Rechercher dans l'historique
const results = massiveContext.searchInHistory(userId, "gaming", 10);
// Retourne les 10 messages les plus pertinents sur le gaming
```

### 4. Base de connaissances globale

Stocke les faits appris de maniÃ¨re persistante :

```json
{
  "facts": {
    "123456789_name": { "value": "John", "confidence": 1.0 },
    "123456789_age": { "value": "25", "confidence": 0.9 },
    "123456789_likes": { 
      "value": ["gaming", "musique", "pizza"],
      "confidence": 0.8 
    }
  }
}
```

## ğŸ“ˆ Performances

### Impact mÃ©moire

| Ã‰lÃ©ment | Taille | Stockage |
|---------|--------|----------|
| Message individuel | ~500 bytes | RAM + Disque |
| RÃ©sumÃ© de 100 msgs | ~2 KB | Disque |
| Base de connaissances | ~50 KB | Disque |
| **Total par utilisateur** | **~100 KB** | **95% Disque** |

### Impact vitesse

- âš¡ Lecture historique : **< 10ms**
- âš¡ Ã‰criture message : **< 5ms**
- âš¡ Compression : **< 50ms** (automatique tous les 100 msgs)
- âš¡ Recherche : **< 20ms**

## ğŸ¯ Utilisation

### Commandes API

```javascript
const massiveContext = require('./massive-context');

// Ajouter un message
massiveContext.addMessage(userId, 'user', 'Salut !', { userName: 'John' });

// Construire le contexte pour l'IA
const context = massiveContext.buildMassiveContext(userId, userName, currentMsg);

// Rechercher dans l'historique
const results = massiveContext.searchInHistory(userId, 'gaming', 10);

// Extraire des connaissances
massiveContext.extractKnowledge(userId, userName, message, response);

// RÃ©cupÃ©rer les faits connus
const facts = massiveContext.getUserKnowledge(userId);
```

## ğŸ”® Perspectives futures

### v1.3
- [ ] Recherche sÃ©mantique avancÃ©e (embeddings)
- [ ] Clustering de conversations par thÃ¨me
- [ ] Export/Import d'historiques
- [ ] Analyse de sentiment avancÃ©e

### v2.0
- [ ] Base de donnÃ©es vectorielle (Pinecone/Weaviate)
- [ ] Recherche cross-utilisateur
- [ ] Graphes de connaissances
- [ ] Apprentissage fÃ©dÃ©rÃ©

## ğŸ› ï¸ DÃ©pannage

### Le bot oublie des choses

1. VÃ©rifiez `AI_MEMORY_LENGTH` dans `.env`
2. Augmentez `OLLAMA_CONTEXT_SIZE`
3. VÃ©rifiez l'espace disque disponible

### RÃ©ponses trop lentes

1. RÃ©duisez `OLLAMA_CONTEXT_SIZE` Ã  16K ou 8K
2. RÃ©duisez `AI_MEMORY_LENGTH` Ã  100
3. Utilisez Mistral 7B au lieu de Mixtral 8x7B

### Fichiers trop volumineux

```bash
# Nettoyer les anciennes conversations
Remove-Item data/conversations/*.json -Force

# RÃ©initialiser la base de connaissances
Remove-Item data/knowledge-base.json -Force
```

## ğŸ“š RÃ©fÃ©rences

- [Ollama Context Size](https://github.com/ollama/ollama/blob/main/docs/faq.md)
- [Mixtral 8x7B](https://mistral.ai/news/mixtral-of-experts/)
- [Token Estimation](https://platform.openai.com/tokenizer)

---

**CrÃ©Ã© avec â¤ï¸ pour BotDsC v1.2**
